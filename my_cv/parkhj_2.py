import cv2
import numpy as np
import pyrealsense2 as rs
import easyocr
import requests
import time
import threading
from PIL import Image, ImageDraw, ImageFont
from queue import Queue, Empty

# =====================================
# 1. DeepL
# =====================================
DEEPL_API_KEY = "1e8f1e6d-24b6-498f-9cc4-0d0ad9f8110d:fx"

CANNY_LOW  = 50
CANNY_HIGH = 150
MIN_AREA = 20000
MAX_AREA = 200000
OCR_INTERVAL = 0.5
ALPHA = 0.3

missing_frame_count = 0 
MAX_MISSING_FRAMES = 5

# ë²ˆì—­ ìš”ì²­/ìºì‹œ
translate_queue = Queue()
translation_cache = {}      # { full_eng(str): kor(str) }
requested_texts  = set()    # ì´ë¯¸ ìš”ì²­ ë„£ì€ ì˜ì–´ ë¬¸ì¥ë“¤


# =====================================
# DeepL ë²ˆì—­ ìŠ¤ë ˆë“œ
# =====================================
def translate(text_eng: str) -> str:
    if not text_eng.strip():
        return "(í…ìŠ¤íŠ¸ ì—†ìŒ)"

    url = "https://api-free.deepl.com/v2/translate"
    headers = {"Authorization": f"DeepL-Auth-Key {DEEPL_API_KEY}"}
    data = {"text": text_eng, "source_lang": "EN", "target_lang": "KO"}

    try:
        r = requests.post(url, headers=headers, data=data, timeout=2.0)
        r.raise_for_status()
        j = r.json()
        t = j.get("translations", [])
        if not t:
            return "(ë²ˆì—­ ì˜¤ë¥˜)"
        return t[0].get("text", "(ë²ˆì—­ ì˜¤ë¥˜)")
    except:
        return "(ë²ˆì—­ ì˜¤ë¥˜)"


def translate_thread():
    global translation_cache
    while True:
        try:
            text_eng = translate_queue.get(timeout=1)
        except Empty:
            continue

        trans = translate(text_eng)
        translation_cache[text_eng] = trans


threading.Thread(target=translate_thread, daemon=True).start()


# =====================================
# ì‚¬ê°í˜• warp í•¨ìˆ˜
# =====================================
def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1)

    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect


def warp_quad(image, quad):
    pts = quad.reshape(4, 2).astype("float32")
    rect = order_points(pts)

    (tl, tr, br, bl) = rect
    widthA = np.linalg.norm(br - bl)
    widthB = np.linalg.norm(tr - tl)
    maxW = int(max(widthA, widthB))

    heightA = np.linalg.norm(tr - br)
    heightB = np.linalg.norm(tl - bl)
    maxH = int(max(heightA, heightB))
    maxW = max(maxW, 40)
    maxH = max(maxH, 40)

    dst = np.array([[0,0],[maxW-1,0],[maxW-1,maxH-1],[0,maxH-1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxW, maxH))

    return warped, M, rect, dst


# =====================================
# ğŸ”¥ ë¬¸ì¥ ë‹¨ìœ„ í´ëŸ¬ìŠ¤í„°ë§
# =====================================
def group_words(results):
    if len(results) == 0:
        return []

    words = []
    for r in results:
        bbox, text, _ = r
        pts = np.array(bbox)

        # bbox ìƒë‹¨ y í‰ê· 
        top_y = int((pts[0][1] + pts[1][1]) / 2)
        # ì¢Œìš° ìˆœì„œ ì•ˆì •í™” â†’ ìµœì†Œ x
        min_x = int(np.min(pts[:,0]))

        words.append((min_x, top_y, bbox, text))

    # ì¤„ ìˆœìœ¼ë¡œ y ì •ë ¬
    words.sort(key=lambda x: x[1])

    clusters = []
    current = [words[0]]

    LINE_GAP = 20
    WORD_GAP = 130

    for i in range(1, len(words)):
        prev = current[-1]
        curr = words[i]

        if abs(prev[1] - curr[1]) < LINE_GAP:
            if abs(prev[0] - curr[0]) < WORD_GAP:
                current.append(curr)
            else:
                clusters.append(current)
                current = [curr]
        else:
            clusters.append(current)
            current = [curr]

    clusters.append(current)

    # ê° í´ëŸ¬ìŠ¤í„° ë‚´ x ì •ë ¬
    for c in clusters:
        c.sort(key=lambda x: x[0])

    return clusters


# =====================================
# overlay ìƒì„± (warp ê³µê°„)
# =====================================
def create_overlay(h, w, word_states):
    """
    word_states: { key: {"eng":..., "kor":..., "bbox":[[x,y],...]} }
    """
    overlay = np.ones((h, w, 3), dtype=np.uint8) * 255
    pil_img = Image.fromarray(overlay)
    draw = ImageDraw.Draw(pil_img)

    for key, st in word_states.items():
        kor = st["kor"]
        bbox = np.array(st["bbox"])

        # bbox ì˜ì—­
        min_x = int(np.min(bbox[:,0]))
        max_x = int(np.max(bbox[:,0]))
        min_y = int(np.min(bbox[:,1]))
        max_y = int(np.max(bbox[:,1]))

        # OCR ê¸€ì”¨ ë†’ì´
        height = max_y - min_y
        if height < 5:
            height = 5

        # 1) ë²ˆì—­ ê¸€ì”¨ í¬ê¸° (ê¸€ì”¨ ë†’ì´ì— ë¹„ë¡€)
        font_size = int(height * 0.5)
        try:
            font = ImageFont.truetype(
                "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                font_size
            )
        except:
            font = ImageFont.load_default()

        # 2) ë²ˆì—­ ê¸€ì”¨ ìœ„ì¹˜ (ê¸€ì”¨ ì•„ë˜ + ë†’ì´ * 0.7)
        text_y = min(max_y + int(height * 0.5), h - height) 

        text = kor
        tb = draw.textbbox((0,0), text, font=font)
        tw = tb[2] - tb[0]

        text_x = min_x + (max_x - min_x)//2 - tw//2

        draw.text((text_x, text_y), text, fill=(0,0,0), font=font)

    return np.array(pil_img)

# main í•¨ìˆ˜ ë°–ì— ì •ì˜ (í˜¹ì€ main í•¨ìˆ˜ ì•ˆì— nested functionìœ¼ë¡œ ì •ì˜)
def select_and_translate_roi(frame, reader):
    """
    í”„ë ˆì„ì—ì„œ ROIë¥¼ ì„ íƒí•˜ê³ , í•´ë‹¹ ì˜ì—­ì˜ í…ìŠ¤íŠ¸ë¥¼ OCR ë° ë²ˆì—­ í›„ íŒì—…ìœ¼ë¡œ í‘œì‹œ
    """
    # 1. ì›ë³¸ í”„ë ˆì„ ë³µì‚¬
    temp_frame = frame.copy()
    
    # 2. ROI ì„ íƒ ì°½ í‘œì‹œ
    win_name = "Select ROI for Translation"
    cv2.namedWindow(win_name)
    
    # ì„ íƒ ì˜ì—­ ì¢Œí‘œ (x, y, w, h)
    ret = cv2.selectROI(win_name, temp_frame)
    cv2.destroyWindow(win_name) # ROI ì„ íƒ í›„ ì°½ ë‹«ê¸°
    
    x, y, w, h = ret
    
    if w > 0 and h > 0:
        # 3. ROI ì˜ì—­ ì˜ë¼ë‚´ê¸°
        roi_img = frame[int(y):int(y+h), int(x):int(x+w)]
        
        # 4. OCR ìˆ˜í–‰
        print("[ROI OCR] Running OCR on selected area...")
        roi_gray = cv2.cvtColor(roi_img, cv2.COLOR_BGR2GRAY)
        
        # EasyOCR ì‹¤í–‰ (WARP ì—†ì´ ë°”ë¡œ ì‹¤í–‰)
        results = reader.readtext(roi_gray, detail=1) 
        
        if not results:
            print("[ROI OCR] No text found in ROI.")
            return

        # 5. í…ìŠ¤íŠ¸ ê·¸ë£¹í™” ë° ë²ˆì—­ ìš”ì²­
        clusters = group_words(results) # ê¸°ì¡´ í•¨ìˆ˜ í™œìš©
        
        all_texts = []
        for cluster in clusters:
            full_eng = " ".join([word[3] for word in cluster]).strip()
            if full_eng:
                all_texts.append(full_eng)
                
        full_eng_text = "\n".join(all_texts)
        
        if not full_eng_text:
            print("[ROI OCR] No meaningful text to translate.")
            return

        # 6. ë™ê¸° ë²ˆì—­ (DeepL ìš”ì²­)
        print("[ROI OCR] Found: '{}'".format(full_eng_text.replace('\n', ' ')))
        kor_translation = translate(full_eng_text)
        
        # 7. ë²ˆì—­ ê²°ê³¼ íŒì—… í‘œì‹œ
        if kor_translation:
        
            # 7-1. ì˜¤ë²„ë ˆì´ í•©ì„± (ì›ë³¸ ì´ë¯¸ì§€ ê¸°ë°˜)
            # roi_img (í¬ë¡­ëœ ì´ë¯¸ì§€)ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
            pil_roi_img = Image.fromarray(cv2.cvtColor(roi_img, cv2.COLOR_BGR2RGB))
            draw = ImageDraw.Draw(pil_roi_img)

            # í°íŠ¸ ë¡œë“œ (ê¸°ì¡´ AR ë²ˆì—­ ë¡œì§ê³¼ ë™ì¼)
            try:
                # ì ì ˆí•œ í°íŠ¸ í¬ê¸° ì„¤ì • (ì˜ˆ: 20)
                font = ImageFont.truetype(
                    "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
                    20 
                )
            except:
                font = ImageFont.load_default()

            # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ROI ì´ë¯¸ì§€ ìœ„ì— ê·¸ë¦½ë‹ˆë‹¤.
            # í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ ì¤„ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ ì¤„ ë°”ê¿ˆ ì²˜ë¦¬
            lines = kor_translation.split('\n')
            y_offset = 10 # ìƒë‹¨ ì—¬ë°±
            
            for line in lines:
                # í…ìŠ¤íŠ¸ì˜ í¬ê¸°ì™€ ìœ„ì¹˜ ê³„ì‚°
                tb = draw.textbbox((0, 0), line, font=font)
                tw = tb[2] - tb[0]
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ë°•ìŠ¤ (ë°˜íˆ¬ëª… ê²€ì€ìƒ‰)
                text_bg_box = [(10, y_offset), (10 + tw + 10, y_offset + 30)] # 30ì€ ëŒ€ëµì ì¸ ì¤„ ë†’ì´
                draw.rectangle(text_bg_box, fill=(0, 0, 0, 180)) # RGBAë¡œ ë°˜íˆ¬ëª… ê²€ì€ìƒ‰
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                draw.text((15, y_offset), line, fill=(255, 255, 255), font=font)
                y_offset += 35 # ë‹¤ìŒ ì¤„ ê°„ê²©
                
            # PIL ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (RGB->BGR)
            result_img_cv = cv2.cvtColor(np.array(pil_roi_img), cv2.COLOR_RGB2BGR)

            # 7-2. ê²°ê³¼ ì°½ í‘œì‹œ ë° ëŒ€ê¸°
            cv2.namedWindow("ROI Translation Result", cv2.WINDOW_AUTOSIZE)
            cv2.imshow("ROI Translation Result", result_img_cv)
            
            # [í•µì‹¬] ì‚¬ìš©ìê°€ ë‹«ì„ ë•Œê¹Œì§€ ëŒ€ê¸° (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ë©”ì¸ ì˜ìƒì€ ì•ˆ ë©ˆì¶¤)
            cv2.waitKey(0) 
            
            # ì°½ ë‹«ê¸°
            cv2.destroyWindow("ROI Translation Result")
            cv2.destroyWindow(win_name)

# =====================================
# 5. ë©”ì¸ (ì—¬ëŸ¬ ì¥ A4 ì§€ì›)
# =====================================
def main():
    global missing_frame_count, MAX_MISSING_FRAMES
    print("Initializing EasyOCR...")
    reader = easyocr.Reader(['en'])

    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
    pipeline.start(config)
    print("RealSense started.")

    last_overlay = None
    last_mask = None
    last_ocr_time = 0.0

    while True:
        frames = pipeline.wait_for_frames()
        f = frames.get_color_frame()
        if not f:
            continue

        frame = np.asanyarray(f.get_data())
        output = frame.copy()
        h, w = frame.shape[:2]
        now = time.time()

        # ----- Canny -----
        g = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        g_blur = cv2.GaussianBlur(g, (5,5), 0)
        edges = cv2.Canny(g_blur, CANNY_LOW, CANNY_HIGH)
        kernel = np.ones((5,5), np.uint8)
        edges = cv2.dilate(edges, kernel, 1)
        edges = cv2.erode(edges, kernel, 1)

        # ----- contour â†’ ì—¬ëŸ¬ ê°œ quad í›„ë³´ -----
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        quads = []

        for cnt in contours:
            peri = cv2.arcLength(cnt, True)
            approx = cv2.approxPolyDP(cnt, 0.02*peri, True)

            if len(approx) == 4:
                if not cv2.isContourConvex(approx):
                    continue
                area = cv2.contourArea(approx)
                if area < MIN_AREA or area > MAX_AREA:
                    continue
                hull = cv2.convexHull(cnt) # ì›ë˜ ì»¨íˆ¬ì–´ë¡œ ì»¨ë²¡ìŠ¤ í— ê³„ì‚°
                hull_area = cv2.contourArea(hull)
                if hull_area == 0: # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€
                    continue
                solidity = float(area) / hull_area
                if solidity < 0.8: # 80% ë¯¸ë§Œì´ë©´ ì œì™¸
                    continue
                x,y,w2,h2 = cv2.boundingRect(approx)
                asp = w2/float(h2)
                if 0.4 < asp < 2.0:
                    quads.append(approx)

        # ----- mask (ì—¬ëŸ¬ ì¢…ì´ union) -----
        mask = None

        if len(quads) > 0:
            # [ì„±ê³µ] ê°ì§€ë˜ì—ˆìœ¼ë¯€ë¡œ ì¹´ìš´í„° ë¦¬ì…‹
            missing_frame_count = 0 
            
            mask = np.zeros((h, w), np.uint8)
            for q in quads:
                cv2.fillConvexPoly(mask, q.reshape(4,2), 255)
        
        else:
            # [ì‹¤íŒ¨] ê°ì§€ ì•ˆ ë¨ -> ì¹´ìš´í„° ì¦ê°€
            missing_frame_count += 1
            
            # [íŒë‹¨] ìœ ì˜ˆ ê¸°ê°„(5í”„ë ˆì„)ì„ ë„˜ê²¼ëŠ”ê°€?
            if missing_frame_count > MAX_MISSING_FRAMES:
                last_mask = None
                last_overlay = None
            else:
                # 5í”„ë ˆì„ì´ ì•ˆ ì§€ë‚¬ìœ¼ë©´, maskëŠ” ì—†ì–´ë„(None)
                # last_overlayì™€ last_maskë¥¼ ì§€ìš°ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
                pass

        # ----- OCR + ë²ˆì—­ (ì—¬ëŸ¬ ì¢…ì´) -----
        if mask is not None and (now - last_ocr_time) > OCR_INTERVAL:
            overlay_total = np.zeros_like(frame, dtype=np.uint8)
            all_texts = []

            for quad in quads:
                warped, M, src, dst = warp_quad(frame, quad)
                warped_gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)

                results = reader.readtext(warped_gray, detail=1)

                clusters = group_words(results)

                # ì´ ì¢…ì´ í•œ ì¥ì— ëŒ€í•œ ìƒíƒœ
                local_states = {}
                state_idx = 0

                for cluster in clusters:
                    full_eng = " ".join([word[3] for word in cluster]).strip()
                    if not full_eng:
                        continue

                    all_texts.append(full_eng)

                    # ë¬¸ì¥ bbox
                    pts_all = []
                    for word in cluster:
                        pts_all.extend(word[2])
                    pts_all = np.array(pts_all)

                    bbox_sentence = [
                        [int(np.min(pts_all[:,0])), int(np.min(pts_all[:,1]))],
                        [int(np.max(pts_all[:,0])), int(np.min(pts_all[:,1]))],
                        [int(np.max(pts_all[:,0])), int(np.max(pts_all[:,1]))],
                        [int(np.min(pts_all[:,0])), int(np.max(pts_all[:,1]))]
                    ]

                    # ë²ˆì—­ ìºì‹œ ì¡°íšŒ / ìš”ì²­
                    kor = translation_cache.get(full_eng)
                    if kor is None:
                        kor = "(ë²ˆì—­ ëŒ€ê¸°ì¤‘)"
                        if full_eng not in requested_texts:
                            translate_queue.put(full_eng)
                            requested_texts.add(full_eng)

                    state = {
                        "eng": full_eng,
                        "kor": kor,
                        "bbox": bbox_sentence
                    }
                    local_states[state_idx] = state
                    state_idx += 1

                # overlay ìƒì„± (warp ê³µê°„)
                if len(local_states) > 0:
                    warp_h, warp_w = warped.shape[:2]
                    warped_overlay = create_overlay(warp_h, warp_w, local_states)

                    # warp-back
                    Minv = cv2.getPerspectiveTransform(dst, src)
                    ov = cv2.warpPerspective(warped_overlay, Minv, (w, h))

                    # ì—¬ëŸ¬ ì¢…ì´ overlayë¥¼ í•©ì„± (ìµœëŒ“ê°’ ì‚¬ìš©)
                    overlay_total = np.maximum(overlay_total, ov)

            if all_texts:
                print("[OCR]", " | ".join(all_texts))
            else:
                print("[OCR] (no text)")

            last_overlay = overlay_total
            last_mask = mask
            last_ocr_time = now

        # ----- ë°˜íˆ¬ëª… í•©ì„± -----
        if last_overlay is not None and last_mask is not None:
            mask_f = (last_mask.astype(np.float32)/255.0)[...,None]
            out_f = output.astype(np.float32)
            ov_f = last_overlay.astype(np.float32)

            output = out_f*(1 - mask_f*ALPHA) + ov_f*(mask_f*ALPHA)
            output = output.astype(np.uint8)

        # ìœ¤ê³½ì„  ë””ë²„ê¹… (ëª¨ë“  ì¢…ì´)
        for q in quads:
            cv2.drawContours(output, [q], -1, (0,255,0), 3)

        cv2.imshow("RealSense AR Translate", output)
        cv2.imshow("Edges", edges)

        k = cv2.waitKey(1)&0xFF
        if k in [27, ord('q')]:
            break
        
        if k == ord('s'):
            # ë©”ì¸ ì˜ìƒì„ ì ì‹œ ë©ˆì¶”ê³  í˜„ì¬ í”„ë ˆì„ ë³µì‚¬
            frame_to_process = frame.copy() 
            roi_thread = threading.Thread(
                target=select_and_translate_roi, 
                args=(frame_to_process, reader), 
                daemon=True # ë©”ì¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í•¨ê»˜ ì¢…ë£Œë˜ë„ë¡ ì„¤ì •
            )
            roi_thread.start()

    pipeline.stop()
    cv2.destroyAllWindows()


if __name__=="__main__":
    main()
